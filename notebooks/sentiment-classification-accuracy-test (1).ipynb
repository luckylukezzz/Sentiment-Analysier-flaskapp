{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 1808590,
     "sourceType": "datasetVersion",
     "datasetId": 989445
    }
   ],
   "dockerImageVersionId": 30761,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import LancasterStemmer\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import LancasterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nimport re\nimport warnings\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:14.095690Z",
     "iopub.execute_input": "2024-08-27T10:41:14.096138Z",
     "iopub.status.idle": "2024-08-27T10:41:16.626307Z",
     "shell.execute_reply.started": "2024-08-27T10:41:14.096095Z",
     "shell.execute_reply": "2024-08-27T10:41:16.625169Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv\n/kaggle/input/sentiment-analysis-dataset/train.csv\n/kaggle/input/sentiment-analysis-dataset/testdata.manual.2009.06.14.csv\n/kaggle/input/sentiment-analysis-dataset/test.csv\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv',\n                 delimiter=',', encoding='ISO-8859-1')\ndf.columns = ['Sentiment','id','date','query','user','text']\ndf.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:16.628232Z",
     "iopub.execute_input": "2024-08-27T10:41:16.628759Z",
     "iopub.status.idle": "2024-08-27T10:41:21.864972Z",
     "shell.execute_reply.started": "2024-08-27T10:41:16.628718Z",
     "shell.execute_reply": "2024-08-27T10:41:21.863512Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "execution_count": 2,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Sentiment          id                          date     query  \\\n0          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n1          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n2          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n3          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n\n            user                                               text  \n0  scotthamilton  is upset that he can't update his Facebook by ...  \n1       mattycus  @Kenichan I dived many times for the ball. Man...  \n2        ElleCTF    my whole body feels itchy and like its on fire   \n3         Karoli  @nationwideclass no, it's not behaving at all....  \n4       joy_wolf                      @Kwesidei not the whole crew   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811372</td>\n      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df = df[['Sentiment','text']]\ndf['Sentiment'] = df['Sentiment'].replace({0: 'negative', 4: 'positive'})\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:21.866342Z",
     "iopub.execute_input": "2024-08-27T10:41:21.866704Z",
     "iopub.status.idle": "2024-08-27T10:41:21.982295Z",
     "shell.execute_reply.started": "2024-08-27T10:41:21.866665Z",
     "shell.execute_reply": "2024-08-27T10:41:21.981313Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df.Sentiment.value_counts()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:21.985776Z",
     "iopub.execute_input": "2024-08-27T10:41:21.986180Z",
     "iopub.status.idle": "2024-08-27T10:41:22.055226Z",
     "shell.execute_reply.started": "2024-08-27T10:41:21.986140Z",
     "shell.execute_reply": "2024-08-27T10:41:22.053805Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "execution_count": 4,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sentiment\nnegative    799996\npositive    248576\nName: count, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from sklearn.utils import resample\n\ndf_positive = df[df['Sentiment'] == 'positive']\ndf_negative = df[df['Sentiment'] == 'negative']\n\n# Downsample majority class\ndf_neg_downsampled = resample(df_negative, \n                                   replace=False,\n                                   n_samples=len(df_positive),\n                                   random_state=42)\n\n# Combine downsampled majority class with minority class\ndf_balanced = pd.concat([df_neg_downsampled, df_positive])\n\n# Shuffle the dataset\ndf_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:22.056795Z",
     "iopub.execute_input": "2024-08-27T10:41:22.057355Z",
     "iopub.status.idle": "2024-08-27T10:41:22.665152Z",
     "shell.execute_reply.started": "2024-08-27T10:41:22.057236Z",
     "shell.execute_reply": "2024-08-27T10:41:22.664023Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df = df_balanced\ndf['Sentiment'] = df['Sentiment'].replace({'negative': 0, 'positive': 1})\nX = df['text']\ny = df['Sentiment']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:22.666615Z",
     "iopub.execute_input": "2024-08-27T10:41:22.667017Z",
     "iopub.status.idle": "2024-08-27T10:41:22.953496Z",
     "shell.execute_reply.started": "2024-08-27T10:41:22.666978Z",
     "shell.execute_reply": "2024-08-27T10:41:22.952369Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_36/1639195524.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df['Sentiment'] = df['Sentiment'].replace({'negative': 0, 'positive': 1})\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df.head",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:22.955574Z",
     "iopub.execute_input": "2024-08-27T10:41:22.956063Z",
     "iopub.status.idle": "2024-08-27T10:41:22.965702Z",
     "shell.execute_reply.started": "2024-08-27T10:41:22.956012Z",
     "shell.execute_reply": "2024-08-27T10:41:22.964174Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "execution_count": 7,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method NDFrame.head of         Sentiment                                               text\n0               1  @firsttiger Real phone? i just read your blog ...\n1               0  is not allowed 2 see her Babyy during  finals....\n2               1  @nicolerichie absolutely, my sister used to pr...\n3               0                 I want holidays!!! Tired of exams \n4               0  @HyunINC I'll be there Sunday night up until T...\n...           ...                                                ...\n497147          1                 Another amusing tweeter: @tinafey \n497148          1             @MichaelMCrowley i saw wolverine too! \n497149          0              Losing my voice  http://myloc.me/2gEs\n497150          0  Just settled down to watch the football, then ...\n497151          0  Lookin for french articles for my oral exam  h...\n\n[497152 rows x 2 columns]>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *Naive Bayes* - CountVectorizer",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "vectorizer = CountVectorizer()\nX_train_vectorized = vectorizer.fit_transform(X_train)\nX_test_vectorized = vectorizer.transform(X_test)\n\n#Create and train the Naive Bayes classifier\nclf = MultinomialNB()\nclf.fit(X_train_vectorized, y_train)\n\n#Make predictions on the test set\ny_pred = clf.predict(X_test_vectorized)\n\n# 7. Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:22.967389Z",
     "iopub.execute_input": "2024-08-27T10:41:22.968378Z",
     "iopub.status.idle": "2024-08-27T10:41:32.049367Z",
     "shell.execute_reply.started": "2024-08-27T10:41:22.968325Z",
     "shell.execute_reply": "2024-08-27T10:41:32.047942Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[40907  8568]\n [13047 36909]]\n              precision    recall  f1-score   support\n\n           0       0.76      0.83      0.79     49475\n           1       0.81      0.74      0.77     49956\n\n    accuracy                           0.78     99431\n   macro avg       0.78      0.78      0.78     99431\nweighted avg       0.79      0.78      0.78     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *Naive Bayes* - TFIDF",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features\n\n# Fit and transform the training data\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)\n\nclf = MultinomialNB()\nclf.fit(X_train_tfidf, y_train)\n\n#Make predictions\ny_pred = clf.predict(X_test_tfidf)\n\n#Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:32.051061Z",
     "iopub.execute_input": "2024-08-27T10:41:32.051556Z",
     "iopub.status.idle": "2024-08-27T10:41:41.841242Z",
     "shell.execute_reply.started": "2024-08-27T10:41:32.051498Z",
     "shell.execute_reply": "2024-08-27T10:41:41.840037Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[38865 10610]\n [12193 37763]]\n              precision    recall  f1-score   support\n\n           0       0.76      0.79      0.77     49475\n           1       0.78      0.76      0.77     49956\n\n    accuracy                           0.77     99431\n   macro avg       0.77      0.77      0.77     99431\nweighted avg       0.77      0.77      0.77     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *Logistic Regression*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(random_state=42)\nclf.fit(X_train_vectorized, y_train)\n\n#Make predictions on the test set\ny_pred = clf.predict(X_test_vectorized)\n\n# 7. Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:41:41.845510Z",
     "iopub.execute_input": "2024-08-27T10:41:41.845956Z",
     "iopub.status.idle": "2024-08-27T10:42:02.032031Z",
     "shell.execute_reply.started": "2024-08-27T10:41:41.845910Z",
     "shell.execute_reply": "2024-08-27T10:42:02.030695Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[[38560 10915]\n [ 9631 40325]]\n              precision    recall  f1-score   support\n\n           0       0.80      0.78      0.79     49475\n           1       0.79      0.81      0.80     49956\n\n    accuracy                           0.79     99431\n   macro avg       0.79      0.79      0.79     99431\nweighted avg       0.79      0.79      0.79     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *Logistic Regression* - TFIDF",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "clf = LogisticRegression(random_state=42)\nclf.fit(X_train_tfidf, y_train)\n\n#Make predictions on the test set\ny_pred = clf.predict(X_test_tfidf)\n\n# 7. Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:42:02.033422Z",
     "iopub.execute_input": "2024-08-27T10:42:02.033908Z",
     "iopub.status.idle": "2024-08-27T10:42:07.525082Z",
     "shell.execute_reply.started": "2024-08-27T10:42:02.033834Z",
     "shell.execute_reply": "2024-08-27T10:42:07.524013Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[[38653 10822]\n [10049 39907]]\n              precision    recall  f1-score   support\n\n           0       0.79      0.78      0.79     49475\n           1       0.79      0.80      0.79     49956\n\n    accuracy                           0.79     99431\n   macro avg       0.79      0.79      0.79     99431\nweighted avg       0.79      0.79      0.79     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *Gradient Boost*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.ensemble import GradientBoostingClassifier\n\nclf = GradientBoostingClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train_tfidf, y_train)\n\ny_pred = clf.predict(X_test_tfidf)\n\n# 7. Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:42:07.526637Z",
     "iopub.execute_input": "2024-08-27T10:42:07.527111Z",
     "iopub.status.idle": "2024-08-27T10:49:16.003032Z",
     "shell.execute_reply.started": "2024-08-27T10:42:07.527061Z",
     "shell.execute_reply": "2024-08-27T10:49:16.001908Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[30818 18657]\n [10948 39008]]\n              precision    recall  f1-score   support\n\n           0       0.74      0.62      0.68     49475\n           1       0.68      0.78      0.72     49956\n\n    accuracy                           0.70     99431\n   macro avg       0.71      0.70      0.70     99431\nweighted avg       0.71      0.70      0.70     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *MLP*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.neural_network import MLPClassifier\n\nclf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\nclf.fit(X_train_tfidf, y_train)\n\ny_pred = clf.predict(X_test_tfidf)\n\n# 7. Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:49:16.004260Z",
     "iopub.execute_input": "2024-08-27T10:49:16.004630Z",
     "iopub.status.idle": "2024-08-27T10:56:19.150215Z",
     "shell.execute_reply.started": "2024-08-27T10:49:16.004588Z",
     "shell.execute_reply": "2024-08-27T10:56:19.149100Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n  warnings.warn(\"Training interrupted by user.\")\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[[39662  9813]\n [11622 38334]]\n              precision    recall  f1-score   support\n\n           0       0.77      0.80      0.79     49475\n           1       0.80      0.77      0.78     49956\n\n    accuracy                           0.78     99431\n   macro avg       0.78      0.78      0.78     99431\nweighted avg       0.78      0.78      0.78     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *Xgboost*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from xgboost import XGBClassifier\n\nclf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nclf.fit(X_train_tfidf, y_train)\n\n# 7. Evaluate the model\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:56:19.151589Z",
     "iopub.execute_input": "2024-08-27T10:56:19.151966Z",
     "iopub.status.idle": "2024-08-27T10:57:07.781886Z",
     "shell.execute_reply.started": "2024-08-27T10:56:19.151930Z",
     "shell.execute_reply": "2024-08-27T10:57:07.780756Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[39662  9813]\n [11622 38334]]\n              precision    recall  f1-score   support\n\n           0       0.77      0.80      0.79     49475\n           1       0.80      0.77      0.78     49956\n\n    accuracy                           0.78     99431\n   macro avg       0.78      0.78      0.78     99431\nweighted avg       0.78      0.78      0.78     99431\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *distilbert-base-uncased*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from transformers import pipeline\nsentiment_task = pipeline(\"sentiment-analysis\")\ny_pred = sentiment_task(X_test.tolist()[:5000])\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T10:57:07.783084Z",
     "iopub.execute_input": "2024-08-27T10:57:07.783417Z",
     "iopub.status.idle": "2024-08-27T11:00:43.251457Z",
     "shell.execute_reply.started": "2024-08-27T10:57:07.783383Z",
     "shell.execute_reply": "2024-08-27T11:00:43.250215Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "text": "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6fcd0d4ed854120b2d81aff5b196cbd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3ffeda8982940a38037ec9ff49b176a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6674cc542d14ed3a9fd15f566e7461f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17884b3a7f554f3382ba7a08735e4140"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "y_pred = pd.DataFrame(y_pred)\ny_pred = y_pred['label']\ny_pred = y_pred.replace({'POSITIVE': 1, 'NEGATIVE': 0})\n\nprint(confusion_matrix(y_test[:5000], y_pred))\nprint(classification_report(y_test[:5000], y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T11:03:37.687191Z",
     "iopub.execute_input": "2024-08-27T11:03:37.687676Z",
     "iopub.status.idle": "2024-08-27T11:03:37.725433Z",
     "shell.execute_reply.started": "2024-08-27T11:03:37.687633Z",
     "shell.execute_reply": "2024-08-27T11:03:37.724394Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[2017  491]\n [ 975 1517]]\n              precision    recall  f1-score   support\n\n           0       0.67      0.80      0.73      2508\n           1       0.76      0.61      0.67      2492\n\n    accuracy                           0.71      5000\n   macro avg       0.71      0.71      0.70      5000\nweighted avg       0.71      0.71      0.70      5000\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_36/466298412.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  y_pred = y_pred.replace({'POSITIVE': 1, 'NEGATIVE': 0})\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *roberta-base*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from transformers import pipeline\nsentiment_task = pipeline(\"sentiment-analysis\", model = 'roberta-base')\ny_pred = sentiment_task(X_test.tolist()[:5000])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T11:03:42.820983Z",
     "iopub.execute_input": "2024-08-27T11:03:42.822053Z",
     "iopub.status.idle": "2024-08-27T11:10:02.818785Z",
     "shell.execute_reply.started": "2024-08-27T11:03:42.822005Z",
     "shell.execute_reply": "2024-08-27T11:10:02.817632Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a15c226f4ea04d008c615c574a5ee4b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47fdc98164bf4a8f8b6358f56870131c"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13c72f58a0bb41e2828968be86801ca9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b07efb6d6c2b4e1da074f9b2ed2d5d61"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6711b821475432e804ecdd32f1204fe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "deeb817a311d4828818bd73de75bab46"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "y_pred = pd.DataFrame(y_pred)\ny_pred = y_pred['label']\n\ny_pred = y_pred.replace({'LABEL_1': 1, 'LABEL_0': 0})\n\nprint(confusion_matrix(y_test[:5000], y_pred))\nprint(classification_report(y_test[:5000], y_pred))\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T11:10:02.860821Z",
     "iopub.execute_input": "2024-08-27T11:10:02.861306Z",
     "iopub.status.idle": "2024-08-27T11:10:02.889963Z",
     "shell.execute_reply.started": "2024-08-27T11:10:02.861244Z",
     "shell.execute_reply": "2024-08-27T11:10:02.888882Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[2508    0]\n [2492    0]]\n              precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67      2508\n           1       0.00      0.00      0.00      2492\n\n    accuracy                           0.50      5000\n   macro avg       0.25      0.50      0.33      5000\nweighted avg       0.25      0.50      0.34      5000\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# *deberta-v3-base-absa-v1.1*",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n\n# Load the ABSA model and tokenizer\nmodel_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nclassifier = pipeline(\"text-classification\", model=model_name, tokenizer=tokenizer)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T11:12:58.068168Z",
     "iopub.execute_input": "2024-08-27T11:12:58.068604Z",
     "iopub.status.idle": "2024-08-27T11:13:40.160016Z",
     "shell.execute_reply.started": "2024-08-27T11:12:58.068566Z",
     "shell.execute_reply": "2024-08-27T11:13:40.158529Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/372 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea8d859d1a0d4aa4b038c95404d1dab2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f63a51c0d4804c759f61bb01aa749d0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff61d7540a1a4b92b5d22386fb337c79"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91939bcb5f4142d78c3e67d62f0d081b"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34d33a1c7006452e91ba7e9e84be2c36"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11e56c48959944fc90b083709f36a809"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "y_pred = classifier(X_test.tolist()[:200])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T11:13:40.162434Z",
     "iopub.execute_input": "2024-08-27T11:13:40.163015Z",
     "iopub.status.idle": "2024-08-27T11:14:21.938642Z",
     "shell.execute_reply.started": "2024-08-27T11:13:40.162964Z",
     "shell.execute_reply": "2024-08-27T11:14:21.937555Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "y_pred = pd.DataFrame(y_pred)\ny_pred\ny_pred = y_pred['label']\n\ny_pred = y_pred.replace({'Positive': 1, 'Negative': 0, 'Neutral':2})\nprint(confusion_matrix(y_test[:200], y_pred))\nprint(classification_report(y_test[:200], y_pred))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-27T11:14:21.940558Z",
     "iopub.execute_input": "2024-08-27T11:14:21.941065Z",
     "iopub.status.idle": "2024-08-27T11:14:21.964447Z",
     "shell.execute_reply.started": "2024-08-27T11:14:21.941014Z",
     "shell.execute_reply": "2024-08-27T11:14:21.962900Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[48 27 24]\n [ 7 63 31]\n [ 0  0  0]]\n              precision    recall  f1-score   support\n\n           0       0.87      0.48      0.62        99\n           1       0.70      0.62      0.66       101\n           2       0.00      0.00      0.00         0\n\n    accuracy                           0.56       200\n   macro avg       0.52      0.37      0.43       200\nweighted avg       0.79      0.56      0.64       200\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_36/2948050310.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  y_pred = y_pred.replace({'Positive': 1, 'Negative': 0, 'Neutral':2})\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}

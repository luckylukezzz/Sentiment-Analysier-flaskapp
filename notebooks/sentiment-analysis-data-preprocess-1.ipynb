{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T04:35:13.555642Z","iopub.execute_input":"2024-07-02T04:35:13.556046Z","iopub.status.idle":"2024-07-02T04:35:17.948558Z","shell.execute_reply.started":"2024-07-02T04:35:13.556012Z","shell.execute_reply":"2024-07-02T04:35:17.947081Z"}}},{"cell_type":"markdown","source":"# Downloading Dataset to Kaggle","metadata":{}},{"cell_type":"code","source":"\nurl = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/meta_categories/meta_Cell_Phones_and_Accessories.jsonl.gz'\nsave_path = 'meta.jsonl.gz'  \nresponse = requests.get(url)\nif response.status_code == 200:\n    with open(save_path, 'wb') as file:\n        file.write(response.content)\n    print(f\"Dataset downloaded successfully to {save_path}\")\nelse:\n    print(f\"Failed to download dataset, status code {response.status_code}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T04:24:59.600394Z","iopub.execute_input":"2024-07-01T04:24:59.600845Z","iopub.status.idle":"2024-07-01T04:26:28.247734Z","shell.execute_reply.started":"2024-07-01T04:24:59.600811Z","shell.execute_reply":"2024-07-01T04:26:28.245810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Specify the path to your JSONL.gz file\nfile_path = 'meta.jsonl.gz'\ntarget_asin = asin_l\n\ndef records_with_asin(file_path, target_asin):\n    matched_records = []\n    with gzip.open(file_path, 'rt') as file:\n        for line in file:\n            record = json.loads(line)\n            if record.get('parent_asin') in target_asin:\n                matched_records.append(record)\n    return matched_records\n\n# Example usage to convert matched records to DataFrame\ndef count_records_with_asin(file_path, target_asin):\n    try:\n        matched_records = records_with_asin(file_path, target_asin)\n        df_matched = pd.DataFrame(matched_records)\n        return df_matched\n    except FileNotFoundError:\n        print(f\"File '{file_path}' not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        \ntry:\n    df_matched = count_records_with_asin(file_path, target_asin)\n    if df_matched is not None:\n        print(\"Matched records:\")\n        print(df_matched)\nexcept Exception as e:\n    print(f\"An error occurred: {str(e)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:50:30.985370Z","iopub.execute_input":"2024-06-30T13:50:30.985940Z","iopub.status.idle":"2024-06-30T13:51:50.405581Z","shell.execute_reply.started":"2024-06-30T13:50:30.985818Z","shell.execute_reply":"2024-06-30T13:51:50.404001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selecting Asin for Required product in Product Data","metadata":{}},{"cell_type":"code","source":"import re\npattern = re.compile(r'Apple iPhone \\d+ \\w+,? \\d+GB,? [\\w\\s]+.*', re.IGNORECASE)\n#pattern2 = re.compile(r'Samsung Galaxy [\\w]*,? \\w* ,? \\d+GB \\w*,?.*', re.IGNORECASE   )\n\n# Search for the pattern in the 'Product_Description' column\nmatches = df_meta['title'].apply(lambda x: bool(pattern.match(x)))\n\n# Filter the DataFrame based on the matches\nfiltered_df = df_meta[matches]\n\nprint(filtered_df.shape)\napple1 = filtered_df['parent_asin'].tolist()\nprint(apple1)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:27:15.732089Z","iopub.execute_input":"2024-07-01T06:27:15.732617Z","iopub.status.idle":"2024-07-01T06:27:16.706963Z","shell.execute_reply.started":"2024-07-01T06:27:15.732581Z","shell.execute_reply":"2024-07-01T06:27:16.705523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gzip\nimport json\n\ndef read_jsonl_gz(file_path):\n    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n        for line in f:\n            yield json.loads(line)\n\n# Create DataFrames from generators\n\ndf_meta = pd.DataFrame(read_jsonl_gz('meta.jsonl.gz'))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:33:35.802223Z","iopub.execute_input":"2024-07-01T06:33:35.802737Z","iopub.status.idle":"2024-07-01T06:35:47.946798Z","shell.execute_reply.started":"2024-07-01T06:33:35.802701Z","shell.execute_reply":"2024-07-01T06:35:47.945180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filtering Products Based on Keywords","metadata":{}},{"cell_type":"code","source":"keywords = ['Apple', 'iPhone','Samsung']\n\nfiltered_df = df_meta[~df_meta['title'].str.contains('|'.join(keywords), case=False, na=False)]\n#filtered_df = filtered_df.dropna()\n\nprint(filtered_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:36:32.691681Z","iopub.execute_input":"2024-07-01T06:36:32.692185Z","iopub.status.idle":"2024-07-01T06:36:53.164691Z","shell.execute_reply.started":"2024-07-01T06:36:32.692149Z","shell.execute_reply":"2024-07-01T06:36:53.163368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_df = filtered_df.drop(columns=['videos','categories','bought_together','subtitle', 'author','main_category'])\nfiltered_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-30T14:36:38.950155Z","iopub.execute_input":"2024-06-30T14:36:38.950660Z","iopub.status.idle":"2024-06-30T14:36:39.077605Z","shell.execute_reply.started":"2024-06-30T14:36:38.950625Z","shell.execute_reply":"2024-06-30T14:36:39.075510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keywords = ['Cell Phones & Accessories']\n\nfiltered_df = df_meta[df_meta['main_category'].str.contains('|'.join(keywords), case=False, na=False)]\n#filtered_df = filtered_df.dropna()\n\nprint(filtered_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:37:22.181641Z","iopub.execute_input":"2024-07-01T06:37:22.182091Z","iopub.status.idle":"2024-07-01T06:37:24.686316Z","shell.execute_reply.started":"2024-07-01T06:37:22.182061Z","shell.execute_reply":"2024-07-01T06:37:24.684904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keywords = ['pixel','Pixel','google','Google']\n\nfiltered_df_na = filtered_df_na[filtered_df_na['title'].str.contains('|'.join(keywords), case=False, na=False)]\n#filtered_df = filtered_df.dropna()\n\nprint(filtered_df_na)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:46:44.952790Z","iopub.execute_input":"2024-07-01T06:46:44.953276Z","iopub.status.idle":"2024-07-01T06:46:45.012677Z","shell.execute_reply.started":"2024-07-01T06:46:44.953216Z","shell.execute_reply":"2024-07-01T06:46:45.011366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_df_na = filtered_df.dropna(subset=['price'])\nfiltered_df_na = filtered_df_na[filtered_df_na['price'] > 60]\nprint(filtered_df_na.head)\nprint(filtered_df_na.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:45:30.942159Z","iopub.execute_input":"2024-07-01T06:45:30.942617Z","iopub.status.idle":"2024-07-01T06:45:31.089138Z","shell.execute_reply.started":"2024-07-01T06:45:30.942583Z","shell.execute_reply":"2024-07-01T06:45:31.087898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keywords_to_drop = ['Screen','iPod','Connector','Bag','Cover','Holder','Samsung','samsung','Apple','apple','iPhone','Galaxy']\n\n# Filter out rows where 'Text' column contains any of the keywords\nfiltered_df = filtered_df[~filtered_df['title'].str.contains('|'.join(keywords_to_drop), case=False, na=False)]\n\nfiltered_df_na = filtered_df.dropna()\nprint(filtered_df)\nprint(filtered_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:45:14.537135Z","iopub.execute_input":"2024-07-01T06:45:14.538321Z","iopub.status.idle":"2024-07-01T06:45:22.662337Z","shell.execute_reply.started":"2024-07-01T06:45:14.538176Z","shell.execute_reply":"2024-07-01T06:45:22.660872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_list = filtered_df_na['parent_asin'].tolist()\nlen(text_list)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:47:00.637057Z","iopub.execute_input":"2024-07-01T06:47:00.640104Z","iopub.status.idle":"2024-07-01T06:47:00.663870Z","shell.execute_reply.started":"2024-07-01T06:47:00.639904Z","shell.execute_reply":"2024-07-01T06:47:00.659957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set1 = set(text_list)\nset2 = set(apple1)\n\n# Combine sets using the union operator \"|\"\ncombined_unique = list(set1 | set2)\nlen(combined_unique)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:30:04.037924Z","iopub.execute_input":"2024-07-01T06:30:04.039239Z","iopub.status.idle":"2024-07-01T06:30:04.049265Z","shell.execute_reply.started":"2024-07-01T06:30:04.039192Z","shell.execute_reply":"2024-07-01T06:30:04.047708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Downloading Reviews Dataset","metadata":{}},{"cell_type":"code","source":"import requests\n\n# Replace 'your_dataset_url' with the actual URL of your dataset\nurl = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/Cell_Phones_and_Accessories.jsonl.gz'\nsave_path = 'Cellphones.jsonl.gz'  # Specify the filename and extension based on your dataset\n\nresponse = requests.get(url)\nif response.status_code == 200:\n    with open(save_path, 'wb') as file:\n        file.write(response.content)\n    print(f\"Dataset downloaded successfully to {save_path}\")\nelse:\n    print(f\"Failed to download dataset, status code {response.status_code}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T04:20:04.520867Z","iopub.execute_input":"2024-07-01T04:20:04.521712Z","iopub.status.idle":"2024-07-01T04:24:13.846184Z","shell.execute_reply.started":"2024-07-01T04:20:04.521663Z","shell.execute_reply":"2024-07-01T04:24:13.844662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gzip\nimport json\nfrom collections import Counter\n\n\ndef top_recurred_items(file_path, column_name, top_n=500):\n    counts = Counter()\n    \n    with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n        for line in file:\n            record = json.loads(line)\n            if column_name in record:\n                counts[record[column_name]] += 1\n\n    top_items = counts.most_common(top_n)\n    return top_items\n\n# Example usage\nfile_path =  'Cellphones.jsonl.gz'\ncolumn_name = 'asin'  \n\ntop_items = top_recurred_items(file_path, column_name)\n#print(\"Top recurring items:\", top_items)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T14:15:07.080429Z","iopub.execute_input":"2024-06-30T14:15:07.081064Z","iopub.status.idle":"2024-06-30T14:20:18.716374Z","shell.execute_reply.started":"2024-06-30T14:15:07.081017Z","shell.execute_reply":"2024-06-30T14:20:18.714103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selecting Reviews Data Based on Asin","metadata":{}},{"cell_type":"markdown","source":"***Json File is Processed in Row wise due to large size***","metadata":{}},{"cell_type":"code","source":"import gzip\nimport json\nfrom collections import Counter\n# Specify the path to your JSONL.gz file\nfile_path = 'Cellphones.jsonl.gz'\n#target_asin = ['B0BY5V82W4', 'B0BXKWGCSW', 'B09JFJ1Q5C', 'B097MBC1P8', 'B08PNTRC2Y', 'B09KW9M48M', 'B0BY5V8P24', 'B099RCQZ8Z', 'B0BV7HZH2F', 'B08PNP57DQ', 'B09JFSMFB5', 'B0BY62TGRN', 'B0BZ1P8CXC', 'B09JFLKR3H', 'B09JFC967X', 'B09JFP3R1D', 'B0BJ1VRNSW', 'B09JF5ZHQS', 'B0BY5V81ST', 'B0BYKZ8TPF', 'B09JFQ9G5Z', 'B09JFQ3P7B', 'B09JFN8K6T', 'B09JFMBNPH', 'B09JF7QNZV', 'B09JFS4P67', 'B09JFTPQY1', 'B0BTMGQ7HY', 'B09JF3PVM2', 'B09JFSH31K', 'B09JFP32Y5', 'B0BV7J3KGX', 'B0BZ9N1QQC', 'B0CJ5PK4HF', 'B0BZZTWXNB', 'B0BWBCC8SV', 'B085T12N5L', 'B0BWCCVW35', 'B0BSLD9D79', 'B0CHZ84Z44', 'B0BQXGVMSL', 'B0C7D4JS8B', 'B0BZ9CCX5K', 'B0BZ9LJPLQ', 'B0BZ9NH985', 'B0CHZ8S5GY', 'B0C3WQW9KC']\ntarget_asin = text_list\ndef records_with_asin(file_path, target_asin):\n    matched_records = []\n    with gzip.open(file_path, 'rt') as file:\n        for line in file:\n            record = json.loads(line)\n            if record.get('asin') in target_asin:\n                matched_records.append(record)\n    return matched_records\n\n# Example usage to convert matched records to DataFrame\ndef count_records_with_asin(file_path, target_asin):\n    try:\n        matched_records = records_with_asin(file_path, target_asin)\n        df_matched = pd.DataFrame(matched_records)\n        return df_matched\n    except FileNotFoundError:\n        print(f\"File '{file_path}' not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        \ntry:\n    df_matched = count_records_with_asin(file_path, target_asin)\n    if df_matched is not None:\n        print(\"Matched records:\")\n        print(df_matched)\nexcept Exception as e:\n    print(f\"An error occurred: {str(e)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:47:11.197371Z","iopub.execute_input":"2024-07-01T06:47:11.197838Z","iopub.status.idle":"2024-07-01T06:53:27.139952Z","shell.execute_reply.started":"2024-07-01T06:47:11.197803Z","shell.execute_reply":"2024-07-01T06:53:27.138571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_matched.to_csv('pixel_products.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:04:27.528058Z","iopub.execute_input":"2024-07-01T07:04:27.528760Z","iopub.status.idle":"2024-07-01T07:04:27.603471Z","shell.execute_reply.started":"2024-07-01T07:04:27.528718Z","shell.execute_reply":"2024-07-01T07:04:27.601610Z"},"trusted":true},"execution_count":null,"outputs":[]}]}